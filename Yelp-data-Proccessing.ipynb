{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184f9f16-f832-437b-906c-49f407b52dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been corrected and saved as 'business_fixed.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"/Users/macbookpro/Downloads/Yelp JSON/yelp_dataset/business.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Fix the incorrect WiFi value if present\n",
    "for entry in data:\n",
    "    attributes = entry.get(\"attributes\")\n",
    "    if attributes and isinstance(attributes, dict) and \"WiFi\" in attributes:\n",
    "        attributes[\"WiFi\"] = \"no\"  # Correcting the WiFi value\n",
    "\n",
    "# Save the corrected JSON\n",
    "with open(\"business_fixed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"JSON data has been corrected and saved as 'business_fixed.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2d6bb8-4ecb-4fe3-b92a-f9eae978c4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed JSON saved to business_fixed.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"business_fixed.json\"\n",
    "\n",
    "with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read().strip()  # Read and strip any leading/trailing spaces\n",
    "\n",
    "# Fix missing brackets if necessary\n",
    "if not content.startswith(\"[\"):\n",
    "    content = \"[\" + content\n",
    "if not content.endswith(\"]\"):\n",
    "    content = content + \"]\"\n",
    "\n",
    "# Remove extra commas before closing brackets\n",
    "content = content.replace(\",]\", \"]\").replace(\",}\", \"}\")\n",
    "\n",
    "# Try parsing again\n",
    "try:\n",
    "    data = json.loads(content)\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, indent=4)  # Save the fixed JSON properly formatted\n",
    "    print(f\"✅ Fixed JSON saved to {file_name}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ JSON is still invalid: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e77e17e-ca61-44e6-bf38-44b349d52b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ business_fixed.json is a valid JSON file!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"business_fixed.json\"\n",
    "\n",
    "try:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read().strip()\n",
    "\n",
    "    # Check if the file is empty\n",
    "    if not content:\n",
    "        raise ValueError(\"File is empty!\")\n",
    "\n",
    "    # Parse JSON\n",
    "    data = json.loads(content)\n",
    "    \n",
    "    print(f\"✅ {file_name} is a valid JSON file!\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ JSON decode error in {file_name} at line {e.lineno}, column {e.colno}: {e.msg}\")\n",
    "\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"❌ Encoding error in {file_name}: {e}\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"❌ {file_name} Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14097e09-8f0f-42cf-9515-c2f19a1c7df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All missing/null values handled in business_fixed.json!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "with open(\"business_fixed.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    businesses = json.load(file)\n",
    "\n",
    "# Function to clean data\n",
    "def clean_business_data(data):\n",
    "    cleaned_data = []\n",
    "    \n",
    "    for business in data:\n",
    "        # Ensure all fields have values\n",
    "        business[\"business_id\"] = business.get(\"business_id\", \"UNKNOWN_ID\")\n",
    "        business[\"name\"] = business.get(\"name\", \"Unknown Name\")\n",
    "        business[\"address\"] = business.get(\"address\", \"No Address\")\n",
    "        business[\"city\"] = business.get(\"city\", \"Unknown City\")\n",
    "        business[\"state\"] = business.get(\"state\", \"Unknown State\")\n",
    "        business[\"postal_code\"] = business.get(\"postal_code\", \"00000\")\n",
    "        business[\"latitude\"] = business.get(\"latitude\", 0.0)\n",
    "        business[\"longitude\"] = business.get(\"longitude\", 0.0)\n",
    "        business[\"stars\"] = business.get(\"stars\", 0.0)\n",
    "        business[\"review_count\"] = business.get(\"review_count\", 0)\n",
    "        business[\"is_open\"] = business.get(\"is_open\", 0)\n",
    "        business[\"attributes\"] = business.get(\"attributes\", {})\n",
    "        business[\"categories\"] = business.get(\"categories\", \"Uncategorized\")\n",
    "        business[\"hours\"] = business.get(\"hours\", {})\n",
    "\n",
    "        cleaned_data.append(business)\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# Process data\n",
    "cleaned_businesses = clean_business_data(businesses)\n",
    "\n",
    "# Overwrite the same file with cleaned data\n",
    "with open(\"business_fixed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(cleaned_businesses, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ All missing/null values handled in business_fixed.json!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43840646-0995-4f35-95a9-841a6ba18919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been corrected and saved as 'checkin_fixed.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"/Users/macbookpro/Downloads/Yelp JSON/yelp_dataset/checkin.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Convert date string to a list\n",
    "for entry in data:\n",
    "    if \"date\" in entry:\n",
    "        entry[\"date\"] = entry[\"date\"].split(\", \")  # Convert to list\n",
    "\n",
    "# Save the corrected JSON\n",
    "with open(\"checkin_fixed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"JSON data has been corrected and saved as 'checkin_fixed.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4528a7a2-82ea-4614-9c40-fa87600add91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ checkin_fixed.json is a valid JSON file!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"checkin_fixed.json\"\n",
    "\n",
    "try:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read().strip()\n",
    "\n",
    "    if not content:\n",
    "        raise ValueError(\"File is empty!\")\n",
    "\n",
    "    json.loads(content)\n",
    "    print(f\"✅ {file_name} is a valid JSON file!\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ JSON decode error in {file_name} at line {e.lineno}, column {e.colno}: {e.msg}\")\n",
    "\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"❌ Encoding error in {file_name}: {e}\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"❌ {file_name} Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "917f4d51-a8c5-4648-b937-b099c1b57076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All missing/null values handled in checkin_fixed.json!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"checkin_fixed.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    checkins = json.load(file)\n",
    "\n",
    "# Function to clean checkin data\n",
    "def clean_checkin_data(data):\n",
    "    cleaned_data = []\n",
    "    \n",
    "    for checkin in data:\n",
    "        checkin[\"business_id\"] = checkin.get(\"business_id\", \"UNKNOWN_ID\")\n",
    "        checkin[\"date\"] = checkin.get(\"date\", \"\")\n",
    "\n",
    "        cleaned_data.append(checkin)\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# Clean the checkin data\n",
    "cleaned_checkins = clean_checkin_data(checkins)\n",
    "\n",
    "# Save the cleaned data back to the file\n",
    "with open(\"checkin_fixed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(cleaned_checkins, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ All missing/null values handled in checkin_fixed.json!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baefc694-e834-49c4-8002-dfb49a431475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_fixed.json has been created with proper JSON format.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the improperly formatted JSON file\n",
    "with open(\"/Users/macbookpro/Downloads/Yelp JSON/yelp_dataset/review.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]  # Read line-by-line and convert each line into a JSON object\n",
    "\n",
    "# Write the corrected JSON format\n",
    "with open(\"review_fixed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(data, file, indent=4)  # Save as a proper JSON array with indentation\n",
    "\n",
    "print(\"review_fixed.json has been created with proper JSON format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537be521-9520-437e-85f2-dac512266378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ review_fixed.json is a valid JSON file!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"review_fixed.json\"\n",
    "\n",
    "try:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read().strip()\n",
    "\n",
    "    if not content:\n",
    "        raise ValueError(\"File is empty!\")\n",
    "\n",
    "    json.loads(content)\n",
    "    print(f\"✅ {file_name} is a valid JSON file!\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ JSON decode error in {file_name} at line {e.lineno}, column {e.colno}: {e.msg}\")\n",
    "\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"❌ Encoding error in {file_name}: {e}\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"❌ {file_name} Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51dce519-2a9c-4830-8f4a-86671cc7f0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All missing/null values handled in review_fixed.json!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"review_fixed.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    reviews = json.load(file)\n",
    "\n",
    "# Function to clean review data\n",
    "def clean_review_data(data):\n",
    "    cleaned_data = []\n",
    "\n",
    "    for review in data:\n",
    "        review[\"review_id\"] = review.get(\"review_id\", \"UNKNOWN_REVIEW\")\n",
    "        review[\"user_id\"] = review.get(\"user_id\", \"UNKNOWN_USER\")\n",
    "        review[\"business_id\"] = review.get(\"business_id\", \"UNKNOWN_BUSINESS\")\n",
    "        review[\"stars\"] = review.get(\"stars\", 0)\n",
    "        review[\"date\"] = review.get(\"date\", \"\")\n",
    "        review[\"text\"] = review.get(\"text\", \"\")\n",
    "        review[\"useful\"] = review.get(\"useful\", 0)\n",
    "        review[\"funny\"] = review.get(\"funny\", 0)\n",
    "        review[\"cool\"] = review.get(\"cool\", 0)\n",
    "\n",
    "        cleaned_data.append(review)\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# Clean the review data\n",
    "cleaned_reviews = clean_review_data(reviews)\n",
    "\n",
    "# Save the cleaned data back to the file\n",
    "with open(\"review_fixed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(cleaned_reviews, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ All missing/null values handled in review_fixed.json!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4cdf408-8462-477f-8dec-bbdea5d8909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tip_fixed.json has been created with proper JSON format.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the improperly formatted JSON file\n",
    "with open(\"/Users/macbookpro/Downloads/Yelp JSON/yelp_dataset/tip.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = [json.loads(line) for line in file]  # Convert each line into a JSON object\n",
    "\n",
    "# Write the corrected JSON format\n",
    "with open(\"tip_fixed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(data, file, indent=4)  # Save as a proper JSON array with indentation\n",
    "\n",
    "print(\"tip_fixed.json has been created with proper JSON format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b7f567-c713-4e49-ab09-c886875572fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ tip_fixed.json is a valid JSON file!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"tip_fixed.json\"\n",
    "\n",
    "try:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read().strip()\n",
    "\n",
    "    if not content:\n",
    "        raise ValueError(\"File is empty!\")\n",
    "\n",
    "    json.loads(content)\n",
    "    print(f\"✅ {file_name} is a valid JSON file!\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ JSON decode error in {file_name} at line {e.lineno}, column {e.colno}: {e.msg}\")\n",
    "\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"❌ Encoding error in {file_name}: {e}\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"❌ {file_name} Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c27a702-9849-424d-983f-30f26ab4c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All missing/null values handled in tip_fixed.json!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"tip_fixed.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    tips = json.load(file)\n",
    "\n",
    "# Function to clean tip data\n",
    "def clean_tip_data(data):\n",
    "    cleaned_data = []\n",
    "\n",
    "    for tip in data:\n",
    "        tip[\"user_id\"] = tip.get(\"user_id\", \"UNKNOWN_USER\")\n",
    "        tip[\"business_id\"] = tip.get(\"business_id\", \"UNKNOWN_BUSINESS\")\n",
    "        tip[\"text\"] = tip.get(\"text\", \"\")\n",
    "        tip[\"date\"] = tip.get(\"date\", \"\")\n",
    "        tip[\"compliment_count\"] = tip.get(\"compliment_count\", 0)\n",
    "\n",
    "        cleaned_data.append(tip)\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# Clean the tip data\n",
    "cleaned_tips = clean_tip_data(tips)\n",
    "\n",
    "# Save the cleaned data back to the file\n",
    "with open(\"tip_fixed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(cleaned_tips, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ All missing/null values handled in tip_fixed.json!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c048e89-d2d5-460b-8ce2-bfc5ec802758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted JSON saved to user_fixed.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"/Users/macbookpro/Downloads/Yelp JSON/yelp_dataset/user.json\"   # Your input file with invalid JSON format\n",
    "output_file = \"user_fixed.json\"  # Output file with proper JSON format\n",
    "\n",
    "# Read the improperly formatted JSON file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Convert lines into a list of JSON objects\n",
    "json_objects = [json.loads(line.strip()) for line in lines]\n",
    "\n",
    "# Write to a new properly formatted JSON file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(json_objects, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Formatted JSON saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26523ee8-32b7-4f43-a8ec-88cd71d57c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ user_fixed.json is a valid JSON file!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"user_fixed.json\"\n",
    "\n",
    "try:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read().strip()\n",
    "\n",
    "    if not content:\n",
    "        raise ValueError(\"File is empty!\")\n",
    "\n",
    "    json.loads(content)\n",
    "    print(f\"✅ {file_name} is a valid JSON file!\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"❌ JSON decode error in {file_name} at line {e.lineno}, column {e.colno}: {e.msg}\")\n",
    "\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"❌ Encoding error in {file_name}: {e}\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"❌ {file_name} Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88a956da-5701-461e-a083-81323ca59f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Missing/null values handled for user_fixed.json!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "with open(\"user_fixed.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    users = json.load(file)\n",
    "\n",
    "# Define required fields and their default values\n",
    "required_fields = {\n",
    "    \"user_id\": \"\",\n",
    "    \"name\": \"Unknown\",\n",
    "    \"review_count\": 0,\n",
    "    \"yelping_since\": \"Unknown\",\n",
    "    \"friends\": [],\n",
    "    \"useful\": 0,\n",
    "    \"funny\": 0,\n",
    "    \"cool\": 0,\n",
    "    \"fans\": 0,\n",
    "    \"elite\": [],\n",
    "    \"average_stars\": 0.0,\n",
    "    \"compliment_hot\": 0,\n",
    "    \"compliment_more\": 0,\n",
    "    \"compliment_profile\": 0\n",
    "}\n",
    "\n",
    "# Process data to handle missing or null values\n",
    "for user in users:\n",
    "    for field, default in required_fields.items():\n",
    "        if user.get(field) is None:  # If key is missing or value is None\n",
    "            user[field] = default\n",
    "\n",
    "# Save the cleaned data back to the file\n",
    "with open(\"user_fixed.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(users, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Missing/null values handled for user_fixed.json!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1045a5d-e948-4936-a63e-fc73c971b916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'business_id': 'Pns2l4eNsfO8kk83dixA6A', 'name': 'Abby Rappoport, LAC, CMQ', 'address': '1616 Chapala St, Ste 2', 'rating': 5.0, 'review_count': 7, 'categories': 'Doctors, Traditional Chinese Medicine, Naturopathic/Holistic, Acupuncture, Health & Medical, Nutritionists', 'coordinates': {'latitude': 34.4266787, 'longitude': -119.7111968}}, {'business_id': 'mpf3x-BjTdTEA3yCZrAYPw', 'name': 'The UPS Store', 'address': '87 Grasso Plaza Shopping Center', 'rating': 3.0, 'review_count': 15, 'categories': 'Shipping Centers, Local Services, Notaries, Mailbox Centers, Printing Services', 'coordinates': {'latitude': 38.551126, 'longitude': -90.335695}}, {'business_id': 'tUFrWirKiKi_TAnsVWINQQ', 'name': 'Target', 'address': '5255 E Broadway Blvd', 'rating': 3.5, 'review_count': 22, 'categories': 'Department Stores, Shopping, Fashion, Home & Garden, Electronics, Furniture Stores', 'coordinates': {'latitude': 32.223236, 'longitude': -110.880452}}, {'business_id': 'MTSW4McQd7CbVtyjqoe9mw', 'name': 'St Honore Pastries', 'address': '935 Race St', 'rating': 4.0, 'review_count': 80, 'categories': 'Restaurants, Food, Bubble Tea, Coffee & Tea, Bakeries', 'coordinates': {'latitude': 39.9555052, 'longitude': -75.1555641}}, {'business_id': 'mWMc6_wTdE0EUBKIGXDVfA', 'name': 'Perkiomen Valley Brewery', 'address': '101 Walnut St', 'rating': 4.5, 'review_count': 13, 'categories': 'Brewpubs, Breweries, Food', 'coordinates': {'latitude': 40.3381827, 'longitude': -75.4716585}}]\n",
      "Data extraction complete. Extracted data saved to 'extracted_business_data.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the entire business_fixed.json file\n",
    "with open('business_fixed.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a list to hold all the extracted data\n",
    "extracted_data = []\n",
    "\n",
    "# Loop through each business in the data\n",
    "for business in data:\n",
    "    # Extract the relevant fields for each business\n",
    "    business_info = {\n",
    "        \"business_id\": business.get(\"business_id\"),\n",
    "        \"name\": business.get(\"name\"),\n",
    "        \"address\": business.get(\"address\"),\n",
    "        \"rating\": business.get(\"stars\"),  # Use 'stars' as rating\n",
    "        \"review_count\": business.get(\"review_count\"),\n",
    "        \"categories\": business.get(\"categories\"),\n",
    "        \"coordinates\": {\n",
    "            \"latitude\": business.get(\"latitude\"),\n",
    "            \"longitude\": business.get(\"longitude\")\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Append the extracted data for this business to the list\n",
    "    extracted_data.append(business_info)\n",
    "\n",
    "# Optionally, print only the first 5 entries to check\n",
    "print(extracted_data[:5])  # Display the first 5 entries\n",
    "\n",
    "# Write the extracted data to a new JSON file to avoid output overflow\n",
    "with open('extracted_business_data.json', 'w') as outfile:\n",
    "    json.dump(extracted_data, outfile, indent=4)\n",
    "\n",
    "print(\"Data extraction complete. Extracted data saved to 'extracted_business_data.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa4665ee-40ea-4cfa-86d9-a8dd8604941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories have been structured. Data updated in 'extracted_business_data.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the previously extracted data from 'extracted_business_data.json'\n",
    "with open('extracted_business_data.json', 'r') as infile:\n",
    "    extracted_data = json.load(infile)\n",
    "\n",
    "# Convert categories to a structured format (list of categories)\n",
    "for business in extracted_data:\n",
    "    # Check if categories is not None before splitting\n",
    "    if business[\"categories\"]:\n",
    "        # Split categories by commas and strip extra spaces\n",
    "        categories_list = [category.strip() for category in business[\"categories\"].split(\",\")]\n",
    "    else:\n",
    "        # If categories is None, assign an empty list\n",
    "        categories_list = []\n",
    "    \n",
    "    # Update the business information with the new categories list\n",
    "    business[\"categories\"] = categories_list\n",
    "\n",
    "# Save the updated data (with structured categories) back to the same file\n",
    "with open('extracted_business_data.json', 'w') as outfile:\n",
    "    json.dump(extracted_data, outfile, indent=4)\n",
    "\n",
    "print(\"Categories have been structured. Data updated in 'extracted_business_data.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aee1f66-e40c-49b3-8296-dcfb595fad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries before removing duplicates: 150346\n",
      "Number of entries after removing duplicates: 150346\n",
      "Duplicates removed and formats standardized. Data updated in 'extracted_business_data.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the previously updated data from 'extracted_business_data.json'\n",
    "with open('extracted_business_data.json', 'r') as infile:\n",
    "    extracted_data = json.load(infile)\n",
    "\n",
    "# Step 1: Check the number of entries before removing duplicates\n",
    "print(\"Number of entries before removing duplicates:\", len(extracted_data))\n",
    "\n",
    "# Remove duplicate entries based on 'business_id'\n",
    "unique_businesses = {}\n",
    "for business in extracted_data:\n",
    "    unique_businesses[business[\"business_id\"]] = business\n",
    "\n",
    "# Convert the dictionary back to a list (with duplicates removed)\n",
    "extracted_data = list(unique_businesses.values())\n",
    "\n",
    "# Step 2: Check the number of entries after removing duplicates\n",
    "print(\"Number of entries after removing duplicates:\", len(extracted_data))\n",
    "\n",
    "# Step 3: Standardize formats (e.g., making names and addresses lowercase, trimming spaces)\n",
    "for business in extracted_data:\n",
    "    # Standardize the 'name' and 'address' fields by stripping spaces and converting to lowercase\n",
    "    business[\"name\"] = business[\"name\"].strip().title()  # Title case for business names\n",
    "    business[\"address\"] = business[\"address\"].strip().title()  # Title case for addresses\n",
    "\n",
    "    # Standardize categories by ensuring all entries are capitalized\n",
    "    business[\"categories\"] = [category.strip().title() for category in business[\"categories\"]]\n",
    "\n",
    "# Save the updated data (with duplicates removed and formats standardized) back to the same file\n",
    "with open('extracted_business_data.json', 'w') as outfile:\n",
    "    json.dump(extracted_data, outfile, indent=4)\n",
    "\n",
    "print(\"Duplicates removed and formats standardized. Data updated in 'extracted_business_data.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2204f53a-36de-4b90-9eaa-4bc587c92fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to CSV files successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Load the extracted JSON data\n",
    "with open('extracted_business_data.json', 'r') as file:\n",
    "    extracted_data = json.load(file)\n",
    "\n",
    "# Open the CSV files for writing\n",
    "with open('businesses.csv', 'w', newline='', encoding='utf-8') as businesses_file, \\\n",
    "     open('categories.csv', 'w', newline='', encoding='utf-8') as categories_file, \\\n",
    "     open('coordinates.csv', 'w', newline='', encoding='utf-8') as coordinates_file:\n",
    "    \n",
    "    # Define CSV writers\n",
    "    business_writer = csv.writer(businesses_file)\n",
    "    category_writer = csv.writer(categories_file)\n",
    "    coordinates_writer = csv.writer(coordinates_file)\n",
    "\n",
    "    # Write the header for each CSV\n",
    "    business_writer.writerow(['business_id', 'name', 'address', 'rating', 'review_count', 'latitude', 'longitude'])\n",
    "    category_writer.writerow(['business_id', 'category'])\n",
    "    coordinates_writer.writerow(['business_id', 'latitude', 'longitude'])\n",
    "\n",
    "    # Process each business entry in the extracted data\n",
    "    for business in extracted_data:\n",
    "        business_id = business['business_id']\n",
    "        name = business['name']\n",
    "        address = business['address']\n",
    "        rating = business['rating']\n",
    "        review_count = business['review_count']\n",
    "        latitude = business['coordinates']['latitude']\n",
    "        longitude = business['coordinates']['longitude']\n",
    "        \n",
    "        # Write business details to the 'businesses.csv'\n",
    "        business_writer.writerow([business_id, name, address, rating, review_count, latitude, longitude])\n",
    "\n",
    "        # Write categories to the 'categories.csv'\n",
    "        if 'categories' in business:\n",
    "            for category in business['categories']:\n",
    "                category_writer.writerow([business_id, category])\n",
    "\n",
    "        # Write coordinates to the 'coordinates.csv'\n",
    "        coordinates_writer.writerow([business_id, latitude, longitude])\n",
    "\n",
    "print(\"Data has been written to CSV files successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4dd006-b96d-493c-a1f9-ac73186692d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.3.5/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f735fe6d-ceb5-4a66-958f-6f6a29069e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business records inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "\n",
    "# Database connection\n",
    "conn = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",  \n",
    "    password=\"sqlpassword123\",  \n",
    "    database=\"YelpDB\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insert first 500 businesses\n",
    "def insert_businesses():\n",
    "    with open(\"businesses.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header row\n",
    "        \n",
    "        count = 0\n",
    "        for row in reader:\n",
    "            if count >= 500:  # Stop after inserting 500 rows\n",
    "                break\n",
    "            try:\n",
    "                sql = \"\"\"\n",
    "                INSERT IGNORE INTO Businesses \n",
    "                (business_id, name, address, rating, review_count, latitude, longitude) \n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "                \"\"\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                count += 1\n",
    "            except pymysql.MySQLError as e:\n",
    "                print(f\"Error inserting business {row[0]}: {e}\")\n",
    "\n",
    "insert_businesses()\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"business records inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b519c4-c271-4626-8e02-4ce7b78badd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows inserted successfully into Categories table!\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "\n",
    "# Database connection\n",
    "conn = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",  \n",
    "    password=\"sqlpassword123\",  \n",
    "    database=\"YelpDB\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insert categories\n",
    "def insert_categories():\n",
    "    with open(\"categories.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header row\n",
    "        count = 0  # Track inserted rows\n",
    "\n",
    "        for row in reader:\n",
    "            if count >= 500:  # Stop after inserting 500 rows\n",
    "                break\n",
    "\n",
    "            business_id, category = row\n",
    "            try:\n",
    "                sql = \"\"\"\n",
    "                INSERT IGNORE INTO Categories (business_id, category) \n",
    "                VALUES (%s, %s);\n",
    "                \"\"\"  \n",
    "                cursor.execute(sql, (business_id, category))\n",
    "                count += 1  # Increment count after successful insert\n",
    "            except pymysql.MySQLError as e:\n",
    "                print(f\"Error inserting category ({business_id}, {category}): {e}\")\n",
    "\n",
    "insert_categories()\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"rows inserted successfully into Categories table!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de8568b-de77-4964-96e5-10aea6b42ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Checkins data extracted to CSV!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Load JSON file\n",
    "with open(\"checkin_fixed.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Write to CSV\n",
    "with open(\"checkins.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"business_id\", \"checkin_date\"])  # Header\n",
    "\n",
    "    for entry in data:\n",
    "        business_id = entry[\"business_id\"]\n",
    "        for checkin_date in entry[\"date\"]:  # Multiple check-ins for one business\n",
    "            writer.writerow([business_id, checkin_date])\n",
    "\n",
    "print(\"✅ Checkins data extracted to CSV!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec8f8ed-cc88-4119-a686-6a4def061a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_10_13_x86_64.whl.metadata (89 kB)\n",
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-9.2.0-cp313-cp313-macosx_14_0_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.2.3-cp313-cp313-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp313-cp313-macosx_10_13_x86_64.whl (12.5 MB)\n",
      "Downloading mysql_connector_python-9.2.0-cp313-cp313-macosx_14_0_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m230.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:02\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-2.2.3-cp313-cp313-macosx_14_0_x86_64.whl (6.7 MB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, mysql-connector-python, pandas\n",
      "Successfully installed mysql-connector-python-9.2.0 numpy-2.2.3 pandas-2.2.3 pytz-2025.1 tzdata-2025.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.3.5/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611226a9-d06e-4d40-a85b-10ef5331ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check-in data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import csv\n",
    "\n",
    "# Database connection\n",
    "conn = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"sqlpassword123\",\n",
    "    database=\"YelpDB\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insert check-ins, ignoring missing business IDs\n",
    "def insert_checkins():\n",
    "    with open(\"checkins.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header row\n",
    "        count = 0  # Limit to 500 rows\n",
    "        for row in reader:\n",
    "            if count >= 500:\n",
    "                break\n",
    "            business_id, checkin_date = row\n",
    "            try:\n",
    "                sql = \"\"\"\n",
    "                INSERT IGNORE INTO Checkins (business_id, checkin_date) \n",
    "                VALUES (%s, %s);\n",
    "                \"\"\"  # INSERT IGNORE will skip invalid rows\n",
    "                cursor.execute(sql, (business_id.strip(), checkin_date.strip()))\n",
    "                count += 1\n",
    "            except pymysql.MySQLError as e:\n",
    "                print(f\"Error inserting check-in ({business_id}, {checkin_date}): {e}\")\n",
    "\n",
    "insert_checkins()\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Check-in data inserted successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
